{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef4713d9-eb6d-47bc-8711-6c0a47447f4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![header](https://storage.googleapis.com/datasets-academy/00%20Databits/01%20Im%C3%A1genes/databits_header.png)\n",
    "\n",
    "# <center>Redes Neuronales Convolucionales</center>\n",
    "**Julio 2020** <br>\n",
    "**Intructor:** Eduardo Marín Nicolalde\n",
    "\n",
    "\n",
    "## Introducción\n",
    "Las Redes Neuronales Convolucionales son redes profundas que implementan dos operaciones básicas:\n",
    "* Convolución \n",
    "* Pooling (sub-sampling). \n",
    "\n",
    "Esta operación ha demostrado ser exitosa en procesos de Visión por Computadora y análisis de Imágenes Médicas. Aunque este tipo de operaciones tiene **aplicaciones limitadas en el análisis y predicción en data tabular**, es importante conocer que se pueden crear este tipo de arquitecturas usando el framework Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cce60552-e12d-4fb1-aa4e-1ce6766bb2ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Objetivos de Aprendizaje\n",
    "Este laboratorio ilustrará como utilizar módulos que implementan la operación de convolución en Keras.\n",
    "\n",
    "* Comprensión básica de las operaciones Conv2D y MaxPooling\n",
    "* Creación de redes neuronales con múltiples capas Conv2D y MaxPooling\n",
    "* Entrenamiento y evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed8af8a0-0f29-435f-b748-f80098ad1ed9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Algoritmo: Red Neuronal Convolutiva\n",
    "### 2.1 Data representation\n",
    "Las redes neuronales Convolutivas se forman por la aplicación de múltiples capas de **convolución y pooling** una a continuación de la otra. La operación de convolución es ampliamente usada en audio (1D) y en imágenes (2D), por lo que para entender esta operación veremos un caso aplicado a imágenes.\n",
    "\n",
    "\n",
    "\n",
    "![Imagen](https://storage.googleapis.com/datasets-academy/ANN/RGBPlanes%402x.png)\n",
    "\n",
    "\n",
    "Las imágenes son almacenadas en dos dimensiones (height, width). Cada pixel es un valor entre 0 y 255. Adicionalmente una imagen fotográfica posee 3 canales (RGB: Rojo, Verde, Azul), por lo que podemos imaginar una imagen representada por 3 matrices de un alto y ancho especifico, una matriz por cada canal. En el lenguaje las matrices multidimensionales de ```numpy``` diríamos que una imagen es un arreglo numpy de dimensiones ```(h,w,3)```. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6aed2f43-6282-4504-b9e8-d39a20a43770",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.2 Convolución\n",
    "\n",
    "La operación convolución es la base de las redes neuronales convolucionales. Para realizarla, se requieren dos elementos:\n",
    "\n",
    "* Imagen de dimensiones (h, w, d)\n",
    "* Filtro de dimensiones (fh,fw,d)\n",
    "* **Output:** (h-fh+1, w-fw+1, 1)\n",
    "\n",
    "![Kernel de Convolucion](https://miro.medium.com/max/576/1*kYSsNpy0b3fIonQya66VSQ.png)\n",
    "\n",
    "Para formar el output se realiza un deslizamiento del filtro a lo largo de toda la imagen. La figura a continuación ilustra este proceso para un solo canal.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/800/1*VJCoCYjnjBBtWDLrugCBYQ.gif\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "En cada deslizamiento, se suma el producto de los valores (elemento por elemento) de cada arreglo numérico dando lugar a la matriz de output\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/516/1*4yv0yIH0nVhSOv3AkLUIiw.png\" width=\"400\"/>\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/335/1*MrGSULUtkXc0Ou07QouV8A.gif\" width=\"200\"/>\n",
    "\n",
    "### 2.3 Filtros\n",
    "Existen un sinnúmero de filtros que permiten detectar distintas características de una imagen. Por ejemplo:\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/436/1*uJpkfkm2Lr72mJtRaqoKZg.png\" />\n",
    "\n",
    "**¿Cómo escoger el filtro correcto?**\n",
    "Existe infintos filtros posibles a aplicar dentro de la convolución. Sin embargo, la matriz de filtros tiene parámetros entrenables de acuerdo al objetivo del modelo. Así, se puede escooger filtros previamente entrenados o usar **backpropagation** para encontrar los valores del filtro que lleven a los mejores resultados.\n",
    "\n",
    "Ejemplo de filtro para detección de bordes verticales (vertical edges)\n",
    "\n",
    "* Imagen ----> <img src=\"https://miro.medium.com/max/584/1*aGSthcPASa2OT1UBm7paOA.png\" width=\"200\"/>\n",
    "\n",
    "* Filtro ----> <img src=\"https://miro.medium.com/max/303/1*591OPcvDKUN9liZ_VQ1M5g.png\" width=\"100\"/>\n",
    "\n",
    "* Output ----> <img src=\"https://miro.medium.com/max/400/1*FkUz4rejmKag4x6j5QC39w.png\" width=\"100\"/> ----> <img src=\"https://miro.medium.com/max/148/1*UHl8cCPMN2GfuR9JRtOfCg.png\" width=\"100\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c0820a85-512f-40d4-8e7f-e67d4972cec5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.4 Padding\n",
    "El comportamiento natural de la aplicación de filtros hace que los píxeles de las esquinas de la imágen no tengan un peso significativo en la capa de output. Adicionalmente, solo  es posible realizar un número finito de convoluciones sobre la imagen.\n",
    "\n",
    "Para resolver este problema, utilizamos la operación **padding** que consiste en añadir bordes alrededor de la imágen, típicamente ceros. \n",
    "\n",
    "<img src=\"https://miro.medium.com/max/674/1*gwEFlk20bWiXGyZkO5r_Xg.png\" width=\"300\"/>\n",
    "\n",
    "### 2.5 Strides \n",
    "Los **strides** hacen referencia a los saltos de pixel que se hacen durante el movimiento del filtro sobre la imagen. \n",
    "\n",
    "Ejemplo de stride 1\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/800/1*g0OmDI1w9KqN7Rpw6Qo8Xg@2x.gif\" width=\"300\"/>\n",
    "\n",
    "Ejemplo de padding + stride 2\n",
    "\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/344/1*GkmFFtArfzTN62uy8Lsf2g.gif\" width=\"300\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "036ad7d5-578a-4d6e-a90b-26e192f10b7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.6 Pooling (subsampling)\n",
    "\n",
    "Consiste en reducir el tamaño espacial de la salida de cada resultado de la convolución y es especialmente util al trabajar con imágenes de alta definición (gran cantidad de pixels). Entre algunos tipos de pooling tenemos:\n",
    "\n",
    "* Max Pooling\n",
    "* Average Pooling\n",
    "* Sum Pooling\n",
    "\n",
    "\n",
    "El más común es **MaxPooling** con un parche de dos en dos. En cada salto se selecciona el máximo valor. Esto permite reducir las dimensiones espaciales (alto y ancho) a la mitad en cada operación de MaxPooling.\n",
    "\n",
    "\n",
    "\n",
    "Finalmente múltiples operaciones de convolución y pooling son añadidas una a continuación de la otra formando una arquitectura de red profunda. Un ejemplo se ilustra a continuación. Usualmente si el problema es de clasificación multi-clase las últimas capas son totalmente conectadas o ```Dense``` (en terminología de Keras), donde al final se aplica una activación tipo Softmax como salida.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/875/1*4GLv7_4BbKXnpc6BRb0Aew.png\" width=\"800\"/>\n",
    "\n",
    "Finalmente los algoritmos de entrenamiento para encontrar los pesos de estas redes son los mismos que hemos visto anteriormente en redes MLP y que se basan en el algoritmo de **backpropagation** (propagación hacia atrás).\n",
    "\n",
    "### 2.7 ¿Por qué CNN?\n",
    "A diferencia de los modelos MLP (perceptrón multicapa), las redes convolucionales tienen menor cantidad de parámetros a aprender debido a :\n",
    "* **Comparten parámetros:** Un mismo filtro puede utilizarse varias veces en distintas etapas de la red.\n",
    "* **Conexión de esparcidad:** Solo un pequeño número de inputs esta directamente relacionado a un output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "999ae1d4-1ff2-4903-a3aa-d69eecf67f8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3. Importar Librerías\n",
    "Las librerías que utilizaremos serán:\n",
    "* ```Python``` (>= 3.6),\n",
    "* ```NumPy``` (>= 1.16.3),\n",
    "* ```Pandas``` (>= 0.24.2),\n",
    "* ```Tensorflow``` (>= 1.13.1),\n",
    "* ```Keras``` (>= 2.2.4),\n",
    "* ```Scikit-learn``` (>= 0.21.1),\n",
    "* ```Matplotlib``` (>= 3.0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9d54497e-7f15-4eb3-9798-381ef72200e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Versión tf:\",tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ecfbb84c-773a-409a-a279-5c493a59a04e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4. Preparación de los datos\n",
    "El siguiente ejemplo es tomado del Libro: Deep Learning with Python (Francois Chollet), capítulo 5.\n",
    "\n",
    "Vamos a utilizar el dataset **MNIST** que consiste en imágenes de dígitos (del 0 al 9):\n",
    "\n",
    "* 60000 imágenes de entrenamiento \n",
    "* 10000 imágenes de testing. \n",
    "* Cada dígito es una imagen en escala de grises de **28x28** píxeles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e378c828-4cde-4987-a293-ecaa38308dc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importar MNIST dataset\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22a91838-bfb9-4312-93cf-88ec06e7ab81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5. Train/Test Split\n",
    "El dataset MNIST ya viene separado en training / testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e095f63-d92d-4fa7-b0ad-a4c8f71f9ad0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Instancia para descargar dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "#Tratamiento y escalamiento de imágenes entrenamiento\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "#Tratamiento y escalamiento de imágenes prueba\n",
    "test_images  = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images  = test_images.astype('float32') / 255\n",
    "\n",
    "#Tratamiento variable objetivo\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels  = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2bfca7c2-b9ef-46ea-a916-a830304d2b97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Visualización de uno de los ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "58ac9927-0db8-476b-bfad-233377b99f3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[5,:,:,0], cmap='gray')\n",
    "plt.show()\n",
    "display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23f5a768-f5bd-42bf-a12a-c52bdaef2b7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 6. Implementación\n",
    "\n",
    "Utilizaremos el modelo  `Sequential` de Keras, al que iremos añadiendo capas. \n",
    "\n",
    "1. **Crear Modelo `Sequencial`**\n",
    "\n",
    "```\n",
    "model = Sequential()\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "Esto crea una instancia ```model```, sobre la cual se pueden ejecutar más operaciones. En particular añadir capas adicionales, compilar el modelo y entrenar el modelo.\n",
    "\n",
    "\n",
    "2.**Añadir las capas que deseemos**\n",
    "\n",
    "```\n",
    "model.add( ... )\n",
    "\n",
    "```\n",
    "\n",
    "Ejemplo: en el caso de **redes convolucionales** añadimos varias capas Conv2D y MaxPool.\n",
    "\n",
    "```\n",
    "input_shape = (28, 28, 1)\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "3.**La última capa corresponde a la salida. Por ejemplo para clasificación multi-clase añadimos una capa `Dense` pero con C unidades (una por cada clase) y con activación Softmax**\n",
    "\n",
    "```\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "```\n",
    "\n",
    "4.**Compilación**\n",
    "\n",
    "\n",
    "```\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "```\n",
    "\n",
    "Una vez armada la red, procedemos a compilarla. En este paso especificamos qué optimizador vamos a utilizar, qué tipo de función de pérdida se va a optimizar y qué métricas utilizaremos. En este caso usamos la pérdida ```categorical_crossentropy``` para un modelo de clasificación de múltiples clases. \n",
    "\n",
    "5.**Entrenamiento**\n",
    "\n",
    "``` \n",
    "history = model.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
    "\n",
    "```\n",
    "Finalmente ejecutaremos el entrenamiento. Aquí debemos especificar los datos (X, y), número de épocas y demás parámetros.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b596560-d0d3-4365-9a7f-2b57b160619b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 7. Documentación \n",
    "\n",
    "A continuación damos un detalle de las clases y  métodos necesarios para entrenar una red convolucional:\n",
    "\n",
    "---\n",
    "**```keras.layers.Conv2D```**\n",
    "Crea una capa que implementa la operación de Convolución 2D:\n",
    "\n",
    "```\n",
    "keras.layers.Conv2D(filters, kernel_size, strides=strides, padding=padding, activation=activation, input_shape=input_shape)\n",
    "\n",
    "```\n",
    "\n",
    "* ```filters``` **integer**. Número de filtros convolutivos que se aplicarán a la entrada de esta unidad.\n",
    "* ```kernel_size```. **tuple de dos valores int**. Dimensión espacial del filtro que se aplicará por ejemplo para un filtro de **5x5**  se especificará ```kernel_size=(5,5)```.\n",
    "* ```strides```. **tuple de dos valores int**. Stride se refiere a cuanto se salta el filtro (en dimensión vertical y horizontal) al desplazarse a lo largo de la entrada. Por defecto es ```(1,1)``` lo que significa que el filtro avanzará de uno en uno.\n",
    "* ```padding```. **string**. Puede ser ```'valid'``` o ```'same'```. Same significa que se rellena los bordes de ceros al calcular la convolución para que las dimensiones espaciales de la salida sean las mismas que las de la entrada.\n",
    "* ```activation``` **string** o instancia de tipo **keras.layers.Activation**. Designa el tipo de función de activación. Tipos comunes son: ```'sigmoid', 'tanh', 'relu', 'softmax'```\n",
    "* ```input_shape``` **tuple** o **integer**. Entero o tupla con la dimensionalidad de la entrada. Para imágenes fotográficas consiste en $ h \\times w \\times ch $, donde $h$ es el número de píxeles del alto, $w$ el número de píxeles del ancho y $ch$ el número de canales (RGB), por ejemplo ```(224, 224, 3)```.\n",
    "\n",
    "---\n",
    "**```keras.layers.MaxPooling2D```**\n",
    "Crea una capa que implementa el subsampling o Max Pooling:\n",
    "\n",
    "```\n",
    "keras.layers.MaxPooling2D(pool_size=pool_size, strides=strides, padding=padding)\n",
    "\n",
    "```\n",
    "\n",
    "* ```pool_size```. **int o tuple de dos valores int**. Indica de cuanto en cuanto hacer el downsampling en la dimension vertical y horizontal.\n",
    "* ```strides```. **tuple de dos valores int**. Stride se refiere a cuanto se salta el filtro (en dimensión vertical y horizontal) al desplazarse a lo largo de la entrada. Por defecto es ```(1,1)``` lo que significa que el filtro avanzará de uno en uno.\n",
    "* ```padding```. **string**. Puede ser ```'valid'``` o ```'same'```. Same significa que se rellena los bordes de ceros al calcular la convolución para que las dimensiones espaciales de la salida sean las mismas que las de la entrada.\n",
    "\n",
    "\n",
    "---\n",
    "**```keras.layers.Flatten```**\n",
    "Como vemos, el producto de las convoluciones en 2D son volúmenes de datos de dimensiones **h x ch**, pero para que puedan ser alimentados a capas totalmente conectadas ```Dense``` se necesita vectores, por lo que esta operación hace la conversión:\n",
    "\n",
    "```\n",
    "keras.layers.Flatten()\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "**Método ```model.fit_generator(generator, steps_per_epoch=steps_per_epoch, epochs=epochs, validation_data=validation_data, validation_steps=validation_steps)```**\n",
    "\n",
    "Método de una instancia tipo ```Sequential```. Suponiendo que se creó el modelo ```model``` y se han compilado las opciones de optimización, se procederá a entrenar. La differencia es que ```fit_generator``` recibe una instancia de un objeto ```generator```. Mediante este objeto se pueden iterar sobre las secuencias a medida que se van generando sin tener que copiar todo a la memoria. Las opciones más importantes son:\n",
    "\n",
    "* ```generator``` **Sequence(keras.utils.Sequence)**. La salida del generador debe proporcionar una tupla ```(inputs, targets)```.\n",
    "* ```steps_per_epoch``` **int**. Número total de pasos (batches de muestras) a proporcionar por el generador.\n",
    "* ```epochs``` **int**. Número de épocas que se va a entrenar el modelo.\n",
    "* ```verbose``` **int**. Nivel de verbosidad. ```0```: modo silencioso. ```1```: sólo muestra la barra de progreso. ```2```: una línea de información por cada época.\n",
    "* ```validation_data``` **tuple o generator**. Datos para la validación. Tupla de pares ```X_val```, ```y_val```, ambos arreglos numpy con el mismo número de columnas de ```X``` y ```y```, aunque no necesariamente el mismo número de filas. También admite un generador para las tuplas de validación.\n",
    "* ```validation_steps``` **int**. Número total de pasos de validación a generar (sólo es válido cuando se usa un ```generator``` como ```validation_data```).\n",
    "* ```callbacks``` **list**. Lista de instancias ```keras.callbacks```. Esto permite ejecutar funciones (callbacks) en cada iteración del proceso (cada época). \n",
    "\n",
    "---\n",
    "**```keras.callbacks.EarlyStopping(monitor=monitor, min_delta=min_delta, patience=patience, verbose=verbose, mode=mode, restore_best_weights=restore_best_weights)```**\n",
    "Callback utilizado para parar proceso de optimización. Las opciones más importantes son:\n",
    "* ```monitor``` **string**. Se refiere a la cantidad que se va a monitorear. Usualmente se monitorea la pérdida sobre los datos de validación. Un valor común es ```monitor='val_loss'```.\n",
    "* ```min_delta``` **float**. Mínimo cambio en la cantidad monitoreada, para que cuantifique como mejoría. Un valor común es ```min_delta=1e-3```\n",
    "* ```patience``` **int**. Número de épocas sin mejoría después de lo cual la optimización se detiene. Ejemplo: ```patience=5```.\n",
    "* ```verbose``` **int**. Modo de verbosidad.\n",
    "* ```mode``` **string**. Usualmente se usa ```mode='auto'```.\n",
    "* ```restore_best_weights``` **boolean**. Indica si se deben restaurar los pesos que derivaron en el mejor valor de la cantidad monitoreada. Usualmente es ```restore_best_weights=True```.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5f813f8-f6cc-479d-b708-7ed867d97768",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear un modelo\n",
    "model = Sequential()\n",
    "# Añadir capas Conv2D y MaxPooling2D\n",
    "\n",
    "# Añade una capa de convolución 2D, con 32 filtros. Cada filtro es de 3x3\n",
    "# se aplica una activación RELU a la salida y el tamaño de la entrada es de\n",
    "# 28x28x1 es decir 28 de altura, 28 de ancho y 1 canal (MNIST es escalas de grises)\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "\n",
    "\n",
    "# Se hace Max Pooling reduciendo a la mitad la dimensión espacial\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "# Añade una capa de convolución 2D, con 64 filtros. Cada filtro es de 3x3\n",
    "# se aplica una activación RELU a la salida\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "\n",
    "# Se hace Max Pooling reduciendo a la mitad la dimensión espacial\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "# Añade una capa de convolución 2D, con 64 filtros. Cada filtro es de 3x3\n",
    "# se aplica una activación RELU a la salida\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "\n",
    "# Para continuar con clasificación multi-clase hay que utilizar capas Dense\n",
    "# Para esto los datos debe ser convertidos a una sola dimensión usando la capa Flatten()\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "\n",
    "# La capa final corresponde a la salida. Una por cada clase\n",
    "# La activación Softmax permite calcular la probabilidad de cada clase (digitos del 0 al 9)\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "# Vemos información sumaria del modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2fa8fbad-ea2c-4fcd-8d0a-7545100ea747",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f31f082-d6a4-4618-811e-d360cba9820d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ba0315a-0aa6-4d90-a952-7c3f9bce594a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compilamos el modelo especificando el algoritmo de optimización, la función de pérdida y las métricas\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenamiento. Esto tomará algún tiempo\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "658c515b-1f79-4f29-9650-9415a2edc303",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 8. Evaluación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7a77958-a99a-4535-ba0f-a28952426340",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Finalmente evaluamos en la data de testing\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Pérdida (testing) = {:.2f}, accuracy (testing) = {:.2f}'.format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7ba02a2-5f2d-4dc1-9e66-2c17f7ea5296",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Fin\n",
    "\n",
    "![texto alternativo](https://storage.googleapis.com/datasets-academy/00%20Databits/01%20Im%C3%A1genes/databits_footer.png)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "04 Convolutional Neural Networks (CNN)",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "name": "04_ConvNets",
  "notebookId": 3598868425426015
 },
 "nbformat": 4,
 "nbformat_minor": 0
}